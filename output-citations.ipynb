{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scholarly as gs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading labs\n",
    "inp_filtered = pd.read_csv('labs_prof_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_cloud(text, title = ''):\n",
    "    short_title = title.split('(')[0].strip()\n",
    "    path = 'cloud_' + short_title + '.png'\n",
    "    if os.path.isfile(path): return\n",
    "    wordcloud = WordCloud(max_words=1000, width=1600, height=800).generate(text)\n",
    "    plt.figure(figsize = (20, 10))\n",
    "    plt.title(title + ' len=' + str(len(text)))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(path, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amin Shokrollahi, ALGO, Algorithmics Laboratory, 246, 19468\n",
      "Pierre Dillenbourg, CHILI, Computer-Human Interaction Lab for Learning & Instruction, 314, 18770\n",
      "Mathieu Salzmann, CVLAB, Computer Vision Laboratory, 468, 36347\n",
      "Christoph Koch, DATA, Data Analysis Theory and Applications Laboratory, 132, 6399\n",
      "Edouard Bugnion, DCSL, Data Center Systems Laboratory, 45, 5692\n",
      "Bryan Alexander Ford, DEDIS, Decentralized and Distributed Systems Lab, 128, 5877\n",
      "Odysseas Papapetrou, DIAS, Data-Intensive Applications and Systems Laboratory, 241, 10769\n",
      "Friedrich Eisenbrand, DISOPT, Discrete Optimization Group (IC/SV), 80, 1698\n",
      "Robert West, DLAB, Data Science Laboratory, 22, 834\n",
      "George Candea, DSLAB, Dependable Systems Laboratory, 95, 5683\n",
      "Martin Rajman, Group Prof. M. Rajman, Group Prof. M. Rajman, 144, 2607\n",
      "Pearl Pu Faltings, HCI, Human-Computer Interaction Group, 160, 4998\n",
      "Ronan Boulic, IIG, Immersive Interaction Group, 154, 5582\n",
      "Sabine Süsstrunk, IVRL, Images and Visual Representation Laboratory, 184, 13505\n",
      "Willy Zwaenepoel, LABOS, Operating Systems Laboratory, 155, 19740\n",
      "Arjen Lenstra, LACAL, Laboratory for cryptologic algorithms, 127, 13971\n",
      "Martin Odersky, LAMP, Programming Methods Laboratory, 212, 11034\n",
      "Alain Wegmann, LAMS, Systemic Modeling Laboratory, 0, 0\n",
      "René Beuchat, LAP, Processor Architecture Laboratory, 204, 5101\n",
      "Viktor Kuncak, LARA, Laboratory for Automated Reasoning and Analysis, 160, 3648\n",
      "Serge Vaudenay, LASEC, Security and Cryptography Laboratory, 226, 7555\n",
      "Jean-Pierre Hubaux, LCA1, Computer Communications and Applications Laboratory 1, 367, 33385\n",
      "Jean-Yves Le Boudec, LCA2, Computer Communications and Applications Laboratory 2, 379, 27203\n",
      "Patrick Thiran, LCA3, Computer Communications and Applications Laboratory 3, 205, 11943\n",
      "Matthias Grossglauser, LCA4, Computer Communications and Applications Laboratory 4, 89, 16985\n",
      "Mihailo Kolundzija, LCAV, Audiovisual Communications Laboratory, 65, 4730\n",
      "Bixio Rimoldi, LCM, Mobile Communications Laboratory, 80, 3008\n",
      "Wulfram Gerstner, LCN, Computational Neuroscience Laboratory (IC/SV), 249, 19779\n",
      "Jeffrey Huang, LDM, Media and Design Laboratory (IC/ENAC), 52, 603\n",
      "Mark Pauly, LGG, Computer Graphics and Geometry Laboratory, 119, 12297\n",
      "Boi Faltings, LIA, Artificial Intelligence Laboratory, 421, 27040\n",
      "Michael C. Gastpar, LINX, Laboratory for Information in Networked Systems, 215, 10918\n",
      "Rachid Guerraoui, LPD, Distributed Programming Laboratory, 544, 21258\n",
      "Giovanni De Micheli, LSI, Integrated Systems Laboratory (IC/STI), 749, 40958\n",
      "Karl Aberer, LSIR, Distributed Information Systems Laboratory, 471, 16063\n",
      "Nicolas Macris, LTHC, Communication Theory Laboratory, 185, 22437\n",
      "Olivier Lévêque, LTHI, Information Theory Laboratory, 140, 20062\n",
      "Christine Vanoirbeek, MEDIA, Models and Environments for Document-based Interaction and Authoring, 0, 0\n",
      "Martin Jaggi, MLO, Machine Learning and Optimization Laboratory, 41, 1594\n",
      "Katerina Argyraki, NAL, Network Architecture Laboratory, 48, 2015\n",
      "Babak Falsafi, PARSA, Parrallel Systems Architecture Laboratory, 165, 11966\n",
      "Mirjana Stojilovic, PARSA BIS, PARSA BIS, 14, 81\n",
      "Wenzel Jakob, RGL, Realistic Graphics Laboratory, 27, 2360\n",
      "Olivier Verscheure, SDSC-GE, Swiss Data Science Center, 120, 3128\n",
      "Bertrand Dutoit, SUPRA, Applied superconductivity, 90, 1259\n",
      "Ola Nils Anders Svensson, THL2, Theory of computation Laboratory 2, 55, 1063\n",
      "Nisheeth Vishnoi, THL3, Theory of Computation Laboratory 3, 0, 0\n",
      "Mikhail Kapralov, THL4, Theory of Computation Laboratory 4, 0, 0\n",
      "Marcel Salathé, UPSALATHE 1, Laboratory of Digital Epidemiology, 52, 3480\n",
      "James Larus, VLSC, Very Large Scale Computing Laboratory, 214, 17904\n",
      "Auke Ijspeert, BIOROB, Biorobotics Laboratory, 306, 14499\n",
      "Kyuhwa Lee, CNBI, Defitech Foundation Chair in Brain-machine Interface - only for Master thesis, 0, 0\n",
      "Michaël Unser, LIB, Biomedical imaging Laboratory, 665, 40807\n",
      "Jean-Marc Odobez, LIDIAP, L'IDIAP Laboratory, 846, 31809\n",
      "Volkan Cevher, LIONS, Laboratory for Information and Inference Systems, 189, 5561\n",
      "Dario Floreano, LIS, Laboratory of Intelligent Systems, 346, 18841\n",
      "Kamiar Aminian, LMAM, Laboratory of Movement Analysis and Measurement, 268, 10404\n",
      "Matteo Cornaglia, LMIS2, Laboratory of Microsystems, 334, 10088\n",
      "Yusuf Leblebici, LSM, Microelectronic Systems Laboratory, 450, 8136\n",
      "Pierre Vandergheynst, LTS2, Signal Processing Laboratory 2, 366, 14587\n",
      "Pascal Frossard, LTS4, Signal Processing Laboratory 4, 374, 7919\n",
      "Jean-Philippe Thiran, LTS5, Signal Processing Laboratory 5, 485, 18361\n",
      "Dimitri Van De Ville, MIPLAB, Medical Image Processing Laboratory, 295, 7766\n",
      "Touradj Ebrahimi, MMSPL, Multimedia Signal Processing Group, 504, 20735\n",
      "Andreas Peter Burg, TCL, Telecommunications Circuits Laboratory, 212, 5065\n",
      "Pavan P Ramdya, UPRAMDYA, Neuroengineering Laboratory Ramdya, 14, 788\n",
      "Alcherio Martinoli, DISAL, Distributed Intelligent Systems and Algorithms Laboratory, 215, 17728\n",
      "Michel Bierlaire, TRANSP-OR, Transportation and Mobility Laboratory, 384, 11144\n",
      "Alexandre Alahi, VITA, Visual Intelligence for Transportation, 41, 2802\n",
      "Frédéric Kaplan, DHLAB, Digital Humanities Laboratory, 158, 4981\n",
      "David Portabella Clotet, IIPP, Chair of Innovation and IP Policy, 0, 0\n"
     ]
    }
   ],
   "source": [
    "all_titles = ''\n",
    "f = open('out.txt', 'w')\n",
    "labs = list(zip(*[inp_filtered[x] for x in list(inp_filtered)]))\n",
    "i = 0\n",
    "for lab in labs:\n",
    "    lab_titles = ''\n",
    "    lab_pubs = 0\n",
    "    lab_cits = 0\n",
    "    short, name, profs = lab\n",
    "    profs = [x.strip() for x in profs.split(',')]\n",
    "    for prof in profs:\n",
    "        filename = 'author-' + str(i) + '.pkl.filled'\n",
    "        i += 1\n",
    "        if not os.path.isfile(filename): continue\n",
    "        author = pickle.load(open(filename, 'rb'))\n",
    "        for paper in author.publications:\n",
    "            try:\n",
    "                title = paper.bib['title']\n",
    "                #year = paper.bib['year']\n",
    "                citedby = paper.citedby\n",
    "                #print((title + ' ') * (1 + (citedby // 1000)))\n",
    "                titles = (title.lower() + ' ') * (1 + (citedby // 1000))\n",
    "                lab_titles += titles\n",
    "                all_titles += titles\n",
    "                lab_pubs += 1\n",
    "                lab_cits += citedby\n",
    "                #print(all_titles)\n",
    "                #break\n",
    "                #f.write('%s\\n' % ', '.join([str(x) for x in [short, prof, title.lower(), year, citedby]]))\n",
    "            except:\n",
    "                #print('Error: ' + str(paper.bib))\n",
    "                pass\n",
    "    print(', '.join([str(x) for x in [prof, short, name, lab_pubs, lab_cits]]))\n",
    "    #if len(lab_titles) > 0:\n",
    "        #show_cloud(lab_titles, title = short + ' (' + name + ')' + ' profs=' + str(profs) + ' cits=' + str(lab_cits) + ' mean=' + str(round(lab_cits / lab_pubs)) + ' papers=' + str(lab_pubs))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_cloud(all_titles, title = 'All (All labs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of all profs\n",
    "profs = [inp_filtered.get_value(i, 'Professors') for i in range(len(inp_filtered))]\n",
    "all_profs = []\n",
    "for prof in profs:\n",
    "    all_profs += [x.strip() for x in prof.split(',')]\n",
    "profs = all_profs\n",
    "del all_profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:00<00:00, 282.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl.filled'\n",
    "    if not os.path.isfile(filename): continue\n",
    "    author = pickle.load(open(filename, 'rb'))\n",
    "    #print(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading labs\n",
    "inp_filtered = pd.read_csv('labs_prof_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of all profs\n",
    "profs = [inp_filtered.get_value(i, 'Professors') for i in range(len(inp_filtered))]\n",
    "all_profs = []\n",
    "for prof in profs:\n",
    "    all_profs += [x.strip() for x in prof.split(',')]\n",
    "profs = all_profs\n",
    "del all_profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### saving one author to a file\n",
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl'\n",
    "    if os.path.isfile(filename): continue\n",
    "    #print(i, prof)\n",
    "    author = gs.search_author(prof + ' epfl')\n",
    "    author = list(author)\n",
    "    #print(author)\n",
    "    # no ambiguity in author search\n",
    "    if len(author) != 1:\n",
    "        print('ERROR PROCESSING ' + prof + ' len=' + str(len(author)))\n",
    "        continue\n",
    "    author = author[0]\n",
    "    with open(filename, 'wb') as f: f.write(pickle.dumps(author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove second names\n",
    "mapping1 = {}\n",
    "mapping1['Bryan Alexander Ford'] = 'Bryan Ford'\n",
    "mapping1['Pearl Pu Faltings'] = 'Pearl Pu'\n",
    "mapping1['Michael C. Gastpar'] = 'Michael Gastpar'\n",
    "mapping1['Ola Nils Anders Svensson'] = 'Ola Svensson'\n",
    "mapping1['François Fleuret'] = 'F Fleuret'\n",
    "mapping1['Martinus Gijs'] = 'Martin Gijs'\n",
    "mapping1['Andreas Peter Burg'] = 'Andreas Burg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### saving one author to a file\n",
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl'\n",
    "    if os.path.isfile(filename): continue\n",
    "    if prof in mapping1.keys():\n",
    "        prof = mapping1[prof]\n",
    "    #print(i, prof)\n",
    "    author = gs.search_author(prof + ' epfl')\n",
    "    author = list(author)\n",
    "    #print(author)\n",
    "    # no ambiguity in author search\n",
    "    if len(author) != 1:\n",
    "        print('ERROR PROCESSING ' + prof + ' len=' + str(len(author)))\n",
    "        continue\n",
    "    author = author[0]\n",
    "    with open(filename, 'wb') as f: f.write(pickle.dumps(author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl'\n",
    "    if os.path.isfile(filename + '.filled'): continue\n",
    "    if not os.path.isfile(filename): continue\n",
    "    author = pickle.load(open(filename, 'rb'))\n",
    "    author.fill()\n",
    "    with open(filename + '.filled', 'wb') as f: f.write(pickle.dumps(author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining original csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = pd.read_csv('labs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = json.loads(open('prof_mapping.txt', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(inp)):\n",
    "    profs_input = [mapping[x.strip()] for x in inp['Professors'][i].split(',')]\n",
    "    inp['Professors'][i] = ', '.join(profs_input)\n",
    "    for col in list(inp.columns):\n",
    "        inp[col][i] = inp[col][i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp.to_csv('labs_prof_filtered.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profs = [inp.get_value(i, 'Professors') for i in range(len(inp))]\n",
    "all_profs = []\n",
    "for prof in profs:\n",
    "    all_profs += [x.strip() for x in prof.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google import google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for prof in all_profs:\n",
    "    if prof in mapping.keys(): continue\n",
    "    search_results = google.search(\"people.epfl.ch \" + prof, 1)\n",
    "    is_found = False\n",
    "    for res in search_results:\n",
    "        title = res.name.split(' : ')\n",
    "        if len(title) == 2 and title[1] == 'Contacts - People@EPFL':\n",
    "            mapping[prof] = title[0]\n",
    "            print(prof + \" === \" + title[0])\n",
    "            is_found = True\n",
    "            break\n",
    "    if not is_found: print('NOT FOUND ' + prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for prof in all_profs:\n",
    "    if prof not in mapping.keys():\n",
    "        print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping['MER B. Dutoit'] = 'Bertrand Dutoit'\n",
    "mapping['MER J.-M. Odobez'] = 'Jean-Marc Odobez'\n",
    "mapping['Dr. M. Cornaglia'] = 'Matteo Cornaglia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('prof_mapping.txt', 'w')\n",
    "f.write(json.dumps(mapping))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
