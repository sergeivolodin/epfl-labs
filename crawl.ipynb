{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scholarly as gs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading labs\n",
    "inp_filtered = pd.read_csv('labs_prof_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_cloud(text, title = ''):\n",
    "    short_title = title.split('(')[0].strip()\n",
    "    path = 'cloud_' + short_title + '.png'\n",
    "    if os.path.isfile(path): return\n",
    "    wordcloud = WordCloud(max_words=1000, width=1600, height=800).generate(text)\n",
    "    plt.figure(figsize = (20, 10))\n",
    "    plt.title(title + ' len=' + str(len(text)))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(path, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = ''\n",
    "f = open('out.txt', 'w')\n",
    "labs = list(zip(*[inp_filtered[x] for x in list(inp_filtered)]))\n",
    "i = 0\n",
    "for lab in labs:\n",
    "    lab_titles = ''\n",
    "    lab_pubs = 0\n",
    "    lab_cits = 0\n",
    "    short, name, profs = lab\n",
    "    profs = [x.strip() for x in profs.split(',')]\n",
    "    for prof in profs:\n",
    "        filename = 'author-' + str(i) + '.pkl.filled'\n",
    "        i += 1\n",
    "        if not os.path.isfile(filename): continue\n",
    "        author = pickle.load(open(filename, 'rb'))\n",
    "        for paper in author.publications:\n",
    "            try:\n",
    "                title = paper.bib['title']\n",
    "                #year = paper.bib['year']\n",
    "                citedby = paper.citedby\n",
    "                #print((title + ' ') * (1 + (citedby // 1000)))\n",
    "                titles = (title.lower() + ' ') * (1 + (citedby // 1000))\n",
    "                lab_titles += titles\n",
    "                all_titles += titles\n",
    "                lab_pubs += 1\n",
    "                lab_cits += citedby\n",
    "                #print(all_titles)\n",
    "                #break\n",
    "                #f.write('%s\\n' % ', '.join([str(x) for x in [short, prof, title.lower(), year, citedby]]))\n",
    "            except:\n",
    "                #print('Error: ' + str(paper.bib))\n",
    "                pass\n",
    "    if len(lab_titles) > 0:\n",
    "        show_cloud(lab_titles, title = short + ' (' + name + ')' + ' profs=' + str(profs) + ' cits=' + str(lab_cits) + ' mean=' + str(round(lab_cits / lab_pubs)) + ' papers=' + str(lab_pubs))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cloud(all_titles, title = 'All (All labs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of all profs\n",
    "profs = [inp_filtered.get_value(i, 'Professors') for i in range(len(inp_filtered))]\n",
    "all_profs = []\n",
    "for prof in profs:\n",
    "    all_profs += [x.strip() for x in prof.split(',')]\n",
    "profs = all_profs\n",
    "del all_profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl.filled'\n",
    "    if not os.path.isfile(filename): continue\n",
    "    author = pickle.load(open(filename, 'rb'))\n",
    "    print(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading labs\n",
    "inp_filtered = pd.read_csv('labs_prof_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of all profs\n",
    "profs = [inp_filtered.get_value(i, 'Professors') for i in range(len(inp_filtered))]\n",
    "all_profs = []\n",
    "for prof in profs:\n",
    "    all_profs += [x.strip() for x in prof.split(',')]\n",
    "profs = all_profs\n",
    "del all_profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### saving one author to a file\n",
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl'\n",
    "    if os.path.isfile(filename): continue\n",
    "    #print(i, prof)\n",
    "    author = gs.search_author(prof + ' epfl')\n",
    "    author = list(author)\n",
    "    #print(author)\n",
    "    # no ambiguity in author search\n",
    "    if len(author) != 1:\n",
    "        print('ERROR PROCESSING ' + prof + ' len=' + str(len(author)))\n",
    "        continue\n",
    "    author = author[0]\n",
    "    with open(filename, 'wb') as f: f.write(pickle.dumps(author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove second names\n",
    "mapping1 = {}\n",
    "mapping1['Bryan Alexander Ford'] = 'Bryan Ford'\n",
    "mapping1['Pearl Pu Faltings'] = 'Pearl Pu'\n",
    "mapping1['Michael C. Gastpar'] = 'Michael Gastpar'\n",
    "mapping1['Ola Nils Anders Svensson'] = 'Ola Svensson'\n",
    "mapping1['Fran√ßois Fleuret'] = 'F Fleuret'\n",
    "mapping1['Martinus Gijs'] = 'Martin Gijs'\n",
    "mapping1['Andreas Peter Burg'] = 'Andreas Burg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### saving one author to a file\n",
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl'\n",
    "    if os.path.isfile(filename): continue\n",
    "    if prof in mapping1.keys():\n",
    "        prof = mapping1[prof]\n",
    "    #print(i, prof)\n",
    "    author = gs.search_author(prof + ' epfl')\n",
    "    author = list(author)\n",
    "    #print(author)\n",
    "    # no ambiguity in author search\n",
    "    if len(author) != 1:\n",
    "        print('ERROR PROCESSING ' + prof + ' len=' + str(len(author)))\n",
    "        continue\n",
    "    author = author[0]\n",
    "    with open(filename, 'wb') as f: f.write(pickle.dumps(author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, prof in enumerate(tqdm(profs)):\n",
    "    filename = 'author-' + str(i) + '.pkl'\n",
    "    if os.path.isfile(filename + '.filled'): continue\n",
    "    if not os.path.isfile(filename): continue\n",
    "    author = pickle.load(open(filename, 'rb'))\n",
    "    author.fill()\n",
    "    with open(filename + '.filled', 'wb') as f: f.write(pickle.dumps(author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining original csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = pd.read_csv('labs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = json.loads(open('prof_mapping.txt', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(inp)):\n",
    "    profs_input = [mapping[x.strip()] for x in inp['Professors'][i].split(',')]\n",
    "    inp['Professors'][i] = ', '.join(profs_input)\n",
    "    for col in list(inp.columns):\n",
    "        inp[col][i] = inp[col][i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp.to_csv('labs_prof_filtered.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profs = [inp.get_value(i, 'Professors') for i in range(len(inp))]\n",
    "all_profs = []\n",
    "for prof in profs:\n",
    "    all_profs += [x.strip() for x in prof.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google import google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for prof in all_profs:\n",
    "    if prof in mapping.keys(): continue\n",
    "    search_results = google.search(\"people.epfl.ch \" + prof, 1)\n",
    "    is_found = False\n",
    "    for res in search_results:\n",
    "        title = res.name.split(' : ')\n",
    "        if len(title) == 2 and title[1] == 'Contacts - People@EPFL':\n",
    "            mapping[prof] = title[0]\n",
    "            print(prof + \" === \" + title[0])\n",
    "            is_found = True\n",
    "            break\n",
    "    if not is_found: print('NOT FOUND ' + prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for prof in all_profs:\n",
    "    if prof not in mapping.keys():\n",
    "        print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping['MER B. Dutoit'] = 'Bertrand Dutoit'\n",
    "mapping['MER J.-M. Odobez'] = 'Jean-Marc Odobez'\n",
    "mapping['Dr. M. Cornaglia'] = 'Matteo Cornaglia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('prof_mapping.txt', 'w')\n",
    "f.write(json.dumps(mapping))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
